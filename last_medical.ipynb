{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "52021395-f139-4bd4-b5bf-7c7414a0aeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.dispatcher:Start polling\n",
      "INFO:aiogram.dispatcher:Run polling for bot @Medical_MVP_testbot id=7620936066 - 'Medical_MVP_test'\n",
      "INFO:aiogram.event:Update id=925368166 is handled. Duration 377 ms by bot id=7620936066\n",
      "INFO:aiogram.event:Update id=925368167 is handled. Duration 3396 ms by bot id=7620936066\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiogram.event:Update id=925368168 is not handled. Duration 9732 ms by bot id=7620936066\n",
      "ERROR:aiogram.event:Cause exception while process update id=925368168 by bot id=7620936066\n",
      "TelegramBadRequest: Telegram server says - Bad Request: message is too long\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/dispatcher.py\", line 309, in _process_update\n",
      "    response = await self.feed_update(bot, update, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/dispatcher.py\", line 158, in feed_update\n",
      "    response = await self.update.wrap_outer_middleware(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/middlewares/error.py\", line 25, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/middlewares/user_context.py\", line 56, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/fsm/middleware.py\", line 42, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/dispatcher.py\", line 276, in _listen_update\n",
      "    return await self.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/router.py\", line 166, in _propagate_event\n",
      "    response = await observer.trigger(event, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/7y/gmykdjhs1x79r8czkvplv5n00000gn/T/ipykernel_12869/3239683500.py\", line 104, in pdf_received\n",
      "    await message.answer(\"üìä –í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤:\\n\\n\" + result)\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/methods/base.py\", line 84, in emit\n",
      "    return await bot(self)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/client/bot.py\", line 478, in __call__\n",
      "    return await self.session(self, method, timeout=request_timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/client/session/base.py\", line 254, in __call__\n",
      "    return cast(TelegramType, await middleware(bot, method))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/client/session/aiohttp.py\", line 185, in make_request\n",
      "    response = self.check_response(\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alfredbeit/Library/r-miniconda/lib/python3.12/site-packages/aiogram/client/session/base.py\", line 120, in check_response\n",
      "    raise TelegramBadRequest(method=method, message=description)\n",
      "aiogram.exceptions.TelegramBadRequest: Telegram server says - Bad Request: message is too long\n",
      "INFO:aiogram.event:Update id=925368169 is handled. Duration 139 ms by bot id=7620936066\n",
      "INFO:aiogram.event:Update id=925368170 is handled. Duration 3451 ms by bot id=7620936066\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:aiogram.event:Update id=925368171 is handled. Duration 8278 ms by bot id=7620936066\n",
      "WARNING:aiogram.dispatcher:Received SIGINT signal\n",
      "INFO:aiogram.dispatcher:Polling stopped for bot @Medical_MVP_testbot id=7620936066 - 'Medical_MVP_test'\n",
      "INFO:aiogram.dispatcher:Polling stopped\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import logging\n",
    "import fitz  # PyMuPDF\n",
    "import markdown2\n",
    "import nest_asyncio\n",
    "from weasyprint import HTML\n",
    "from aiogram import Bot, Dispatcher, types\n",
    "from aiogram.types import FSInputFile\n",
    "from aiogram.enums import ParseMode\n",
    "from aiogram.filters import CommandStart, StateFilter\n",
    "from aiogram.fsm.storage.memory import MemoryStorage\n",
    "from aiogram.fsm.context import FSMContext\n",
    "from aiogram.fsm.state import StatesGroup, State\n",
    "from aiogram.types import Document\n",
    "from groq import Groq\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "API_TOKEN = \"7620936066:AAERVNuOoIxzZbl4MuIjzeWH3XMyFE4ko7c\"\n",
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "bot = Bot(token=API_TOKEN)\n",
    "dp = Dispatcher(storage=MemoryStorage())\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# === FSM STATE ===\n",
    "class CompareStates(StatesGroup):\n",
    "    waiting_for_pdfs = State()\n",
    "\n",
    "user_files = {}\n",
    "\n",
    "# === PDF TEXT EXTRACTION ===\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# === GROQ COMPARISON ===\n",
    "def compare_texts(text1, text2):\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "    –¢—ã ‚Äî –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫. –°—Ä–∞–≤–Ω–∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞. –¢—ã –æ–±—â–∞–µ—à—å—Å—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
    "    \n",
    "    –ü—Ä–µ–¥—Å—Ç–∞–≤—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ, –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ë–ï–ó Markdown –∏–ª–∏ HTML. \n",
    "        –®–∞–±–ª–æ–Ω –¥–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è:\n",
    "                    –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å: –õ–∏–º—Ñ–æ—Ü–∏—Ç—ã (LYM)\n",
    "                    –î–∞—Ç–∞ –≤–∑—è—Ç–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞: 24.05.2023\n",
    "                    –ó–Ω–∞—á–µ–Ω–∏–µ: 2.39 —Ö10^9/–ª   \n",
    "                    –î–∞—Ç–∞ –≤–∑—è—Ç–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞: 26.12.2023\n",
    "                    –ó–Ω–∞—á–µ–Ω–∏–µ: 2.39 —Ö10^9/–ª\n",
    "                    –†–µ—Ñ–µ—Ä–µ–Ω—Å: 1.00-4.80 —Ö10^9/–ª\n",
    "...\n",
    "\n",
    "    –ê–Ω–∞–ª–∏–∑ 1:\n",
    "    {text1}\n",
    "    \n",
    "    –ê–Ω–∞–ª–∏–∑ 2:\n",
    "    {text2}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"–¢—ã –≤—Ä–∞—á –æ–±—â–µ–π –ø—Ä–∞–∫—Ç–∏–∫–∏, –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# === COMMAND START ===\n",
    "@dp.message(CommandStart())\n",
    "async def start_command(message: types.Message, state: FSMContext):\n",
    "    await message.answer(\"üëã –ü—Ä–∏–≤–µ—Ç! –ü—Ä–∏—à–ª–∏ –¥–≤–∞ PDF-—Ñ–∞–π–ª–∞ —Å –∞–Ω–∞–ª–∏–∑–∞–º–∏ (–ø–æ –æ–¥–Ω–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –Ω–∞ —Ñ–∞–π–ª).\")\n",
    "    user_files[message.from_user.id] = []\n",
    "    await state.set_state(CompareStates.waiting_for_pdfs)\n",
    "\n",
    "# === PDF RECEIVED ===\n",
    "@dp.message(StateFilter(CompareStates.waiting_for_pdfs))\n",
    "async def pdf_received(message: types.Message, state: FSMContext):\n",
    "    if not message.document:\n",
    "        await message.answer(\"‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å PDF-—Ñ–∞–π–ª.\")\n",
    "        return\n",
    "\n",
    "    user_id = message.from_user.id\n",
    "    file = await bot.download(message.document)\n",
    "    file_path = f\"user_{user_id}_{len(user_files[user_id]) + 1}.pdf\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file.read())\n",
    "    user_files[user_id].append(file_path)\n",
    "\n",
    "    if len(user_files[user_id]) < 2:\n",
    "        await message.answer(\"‚úÖ –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω. –ñ–¥—É –µ—â—ë –æ–¥–∏–Ω PDF.\")\n",
    "    else:\n",
    "        await message.answer(\"üîç –°—Ä–∞–≤–Ω–∏–≤–∞—é –∞–Ω–∞–ª–∏–∑—ã...\")\n",
    "\n",
    "        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
    "        text1 = extract_text_from_pdf(user_files[user_id][0])\n",
    "        text2 = extract_text_from_pdf(user_files[user_id][1])\n",
    "        result = compare_texts(text1, text2)\n",
    "\n",
    "        await message.answer(\"üìä –í–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤:\\n\\n\" + result)\n",
    "\n",
    "        # --- –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "        for path in user_files[user_id]:\n",
    "            os.remove(path)\n",
    "        user_files[user_id] = []\n",
    "        \n",
    "\n",
    "# === –ó–ê–ü–£–°–ö –í JUPYTER ===\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "await dp.start_polling(bot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a2fb1-dc0f-487d-a55e-007f3caca2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297690b6-2507-40c8-87ca-e15c4c9a20b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:r-miniconda]",
   "language": "python",
   "name": "conda-env-r-miniconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
